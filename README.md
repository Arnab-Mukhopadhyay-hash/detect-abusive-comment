# detect-abusive-comment

An increasing number of Bengali users of social media post a lot of status updates, along with images, comments, and other content, to which others can respond right away. Generally, this frequently produces text with negative comments that must be filtered out. With lists of offensive words and intricate regulations, manually filtering toxic comments is a difficult task, especially for inflectional languages like Bengali. Social media text is unstructured, which adds to its difficulty and low acceptability score. It was previously difficult to write handwritten rules using manual linguistic features, but automated systems and inexpensive computing resources have changed this situation. A component of Natural Language Processing (NLP) is the computational extraction of salient features from textual data. NLP requires an annotated corpus to convey information related to various applications, one of which is the detection of toxic comments. Scholars have attempted to identify sentence toxicity using statistical machine-learning models. However, these models don't work well with unstructured social media comments because they need frequency-based feature engineering or probabilistic phenomena. By capturing low-level features and combining them into layer-wise abstractions, deep learning-based models have demonstrated their efficacy in addressing these limitations. Various studies have demonstrated the significant superiority of these models over other supervised machine learning models in the context of English text analysis. We have examined that assertion for detecting Bengali toxic comment material in this academic work.

It is laborious to manually create rules to filter such offensive comments because they are disorganized and frequently contain vulgar words spelled incorrectly. Sentiment analysis includes automated machine learning-based models for classifying such toxic comments. These models are widely used for the English language and exhibit more promising outcomes than statistical models. Despite being a language that is spoken by many people, not much research has been done to identify harmful remarks in Bengali. Therefore, to identify harmful Bengali comments from an annotated dataset, we compare four supervised learning models â€” Random Forest, Naive Bayes, Support Vector Machines, Logistic Regression, with our implemented model Bangla - Bidirectional Encoder Representations from Transformers [BanglaBERT] and Long Short Term Memory(LSTM).

